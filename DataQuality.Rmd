# データの質 {#DataQuality}


*Chapter leads: Martijn Schuemie, Vojtech Huser & Clair Blacketer* 

観察医療研究に使用されたデータのほとんどは、研究目的のために収集されたものではない。例えば、電子カルテ（EHR）は患者のケアをサポートするために必要な情報を収集することを目的としており、行政請求書は支払者への費用配分の根拠とするために収集されている。このようなデータを臨床研究に使用することが適切かどうかについては多くの人が疑問視しており、Lei (1991)は "データは収集した目的のためにのみ使用されるものとする "とまで述べている。懸念されるのは、自分たちがやりたい研究のために収集したデータではないので、十分な品質が保証されていないということです。データの質が悪い（ゴミが入る）のであれば、そのデータを使った研究結果の質も悪い（ゴミが出る）はずである。したがって、観察的ヘルスケア研究の重要な側面は、データの質を評価することであり、その質問に答えることを目的としている。

> 관찰형 의료 연구에서 사용되는 대부분의 데이터는 연구를 목적으로 수집되지 않는다. 예를 들어, 전자 의무 기록(Electronic Health Records, EHR)은 환자의 진료를 지원하는데 필요한 정보를 수집하기 위해, 청구 데이터는 비용 지불자에게 비용을 할당하기 위한 근거를 제공하기 위해 수집된다. 많은 이들이 이러한 데이터를 임상 연구에 사용하는것이 적합한가 여부에 의문을 가지고 있으며 심지어, @vanDerLei_1991 은 "데이터는 수집된 목적으로만 사용되어야 한다(Data shall be used only for the purpose for which they were collected)"고 주장하였다. 문제는 데이터가 우리가 원하는 연구를 위해 수집되지 않았기 때문에, 충분한 품질을 보장할 수 없다는 것이다. 데이터의 품질이 낮으면 (garbage in), 그 데이터를 사용한 연구 결과의 품질도 낮을 수밖에 없다 (garbage out). 따라서 관찰형 의료 연구에 있어서 데이터 품질을 평가하는 것은 중요하며, 다음의 질문에 대한 답을 목표로 한다:

> 研究目的に適したデータか (Are the data of sufficient quality for our research purposes) ?

データ品質（DQ）を（Roebuck 2012）と定義することができます。 [@roebuck_2012]: \index{data quality}

データの完全性、妥当性、整合性、適時性、正確性など、特定の用途に適したデータとなる状態。
> 데이터를 특정 목적에 적합하게 만드는 완전성(Completeness), 유효성(Validity), 일관성(Consistency), 적시성(Timeliness), 정확성(Accuracy)의 상태 (The state of completeness, validity, consistency, timeliness and accuracy that makes data appropriate for a specific use).

我々のデータが完全である可能性は低いが、我々の目的には十分であるかもしれないことに注意。

DQは直接観察することはできないが、それを評価するための方法論が開発されている。DQの評価には2つのタイプがある（Weiskopf and Weng 2013）。一般的にDQを評価するための評価と、特定の研究の文脈でDQを評価するための評価である。

本章では、まずDQ問題の発生源となりうるものをレビューし、その後、一般的なDQ評価と研究固有のDQ評価の理論を議論し、OHDSIツールを使用してこれらの評価をどのように実行するかをステップバイステップで説明していきます。

> 주목할만한 것은 우리의 데이터가 완벽하지는 않지만, 목적에 충분히 적합할 수 있다는 것이다. 

DQ를 직접적으로 관찰할 수는 없지만, 이를 평가하기 위한 방법론이 개발되어 왔다. DQ 평가는 2가지 유형으로 구분될 수 있다 [@weiskopf_2013]: 보편적인 DQ를 확인하기 위한 평가, 특정 연구의 맥락에서 DQ를 확인하기 위한 평가.

본 장에서 우리는 먼저, DQ 문제가 발생할 수 있는 원인에 대해 검토하고, 보편적인 DQ와 연구 목적의 DQ 평가 이론에 대해 논의 후, OHDSI 툴들을 사용하여 이러한 평가를 어떻게 수행하는지 단계별로 설명하고자 한다. 

## データ品質問題の原因

第14章で述べたように、医師が自分の考えを記録するところから始まり、データの品質には多くの脅威がある。Dasu and Johnson（2003）は、データのライフサイクルにおける以下のステップを区別し、各ステップにDQを統合することを推奨している。彼らはこれをDQ連続体と呼んでいる。

> \@ref(EvidenceQuality)장에서 언급한 바와 같이, 의사들이 본인의 생각을 기록할 때 데이터 품질과 관련된 많은 위험요소가 발생한다. @dasu_2003 은 데이터의 수명 주기에 따른 단계를 명시하였고, 각 단계를 통합한 DQ 진행을 제시하였다. 그들은 이를 DQ 연속체(DQ continuum)라 하였다:

データ収集と統合。考えられる問題には、間違いやすい手入力、偏り（クレームのアップコーディングなど）、EHR内のテーブルの誤った結合、欠落している値をデフォルトの値に置き換えることなどがあります。
データの保存と知識の共有。潜在的な問題としては、データモデルの文書化が不足していること、およびメタデータが不足していることが挙げられます。
データ分析。問題には、不正確なデータ変換、不正確なデータ解釈、不適切な方法論の使用などがあります。
データの公開。下流での使用のためにデータを公開するとき。

1. **데이터 수집 및 통합(Data gathering and integration)**. 자료의 수기 입력시 오류와 비뚤림등의 발생가능한 문제 (예를 들어 upcoding in claims; 청구를 위하여 진단명과 시술 등을 보다 심각하게 혹은 높은 비용으로 작성하는것), EHR에서 잘못된 테이블간의 결합, 결측값을 기본값으로 대체하는 것 등을 포함한다. 
2. **데이터 저장 및 지식 공유(Data storage and knowledge sharing)**. 데이터 모델에 대한 문서화 부족, 메타 데이터의 부족이 잠재적인 문제로 여겨진다. 
3. **데이터 분석(Data analysis)**. 잘못된 데이터 변환, 부정확한 데이터 해석, 그리고 부적절한 방법론 사용 등의 문제가 포함될 수 있다. 
4. **데이터 공유(Data publishing)**. 후속 사용을 위해 데이터를 게시하는 경우 (When publishing data for downstream use).

多くの場合、使用するデータはすでに収集され、統合されているので、ステップ1を改善するためにできることはほとんどありません。この章の後続のセクションで説明するように、このステップで生成されたDQをチェックする方法はあります。

> 우리가 사용하는 데이터는 대부분 이미 수집되고 통합되어 있기 때문에, 1단계에서 개선할 수 있는 것은 거의 없다. 이 단계에서 생성된 DQ를 확인할 방법은 다음 절에서 논의될 것이다. 

同様に、我々はデータを特定の形式で受け取ることが多いので、ステップ2の一部にはほとんど影響を与えません。しかし、OHDSIでは、すべての観測データを共通データモデル（CDM）に変換しており、このプロセスのオーナーシップを持っています。この特定のステップがDQを劣化させるのではないかという懸念を表明している人もいます。しかし、我々はこのプロセスを制御しているので、後述の15.2.2節で説明するように、DQを維持するための厳格なセーフガードを構築することができます。いくつかの調査（Defalco, Ryan, and Soledadad Cepeda 2013; Makadia and Ryan 2014; Matcho et al. 2014; Voss, Ma, and Ryan 2015; Voss et al. 2015; Hripcsak et al. 2018）は、適切に実行された場合、CDMへの変換時にほとんどエラーが導入されないことを示している。実際、大規模なコミュニティで共有されているデータモデルを十分に文書化しておくことで、曖昧さのない明確な方法でのデータ保存が容易になります。

ステップ 3（データ分析）も我々の管理下にある。OHDSI では、このステップでの品質問題については DQ という用語を使用せず、臨床的妥当性、ソフトウェアの妥当性、方法の妥当性という用語を使用する傾向がある。

> 유사하게, 특정 형식으로 데이터를 받기 때문에 2단계에 대한 영향을 줄 수 있는 부분도 미미하다. 하지만 OHDSI에서 우리는 우리의 관찰 데이터를 공통 데이터모델(Common Data Model, CDM)로 변환하고, 이 프로세스에 대한 소유권을 갖는다. 몇몇은 이러한 특정 단계가 DQ를 저하할 것이라 우려를 표한다. 하지만 우리는 이 변환 프로세스를 통제하기 때문에, 이후 \@ref(etlUnitTests)절에서 논의하는 것과 같이 DQ를 보존하기 위한 엄격한 안전장치를 구축할 수 있다. 여러 연구[@defalco_2013;@makadia_2014;@matcho_2014;@voss_2015;@voss_2015b;@hripcsak_2018]에 따르면 이 과정이 제대로 실행된다면 CDM으로 변환했을 때 오류가 거의 발생하지 않는 것으로 나타났다. 실제로, 대규모 공동체에 의해 공유되는 잘 문서화된 데이터 모델은 명백하고 명확한 방법으로 데이터 저장을 용이하게 한다. 

3단계 (데이터 분석) 또한 우리의 통제 아래에 있다. OHDSI에서 우리는 이 단계의 품질 이슈에 대해 DQ 용어를 사용하지 않고 각각 \@ref(ClinicalValidity)장, \@ref(SoftwareValidity)장, 그리고 \@ref(MethodValidity)장에서 다루는 *clinical validity*, *software validity* 그리고 *method validity*라는 용어를 사용한다. 

## 一般的なデータ品質

我々は、我々のデータが観測研究の一般的な目的に適合しているかどうかを問うことができる。Kahnら（2016）は、このような汎用DQを3つの構成要素からなるものと定義している。

> 우리는 우리의 데이터가 관찰형 연구의 보편적인 목적에 적합한지 여부에 대해 의문을 가질 수 있다. @kahn_harmonized_2016 은 보편적인 DQ가 3가지 구성요소로 구성되어있다고 정의하였다: 

適合性。データ値は指定された規格やフォーマットに準拠しているか？3つのサブタイプが確認されています。
値。記録されたデータ要素は、指定されたフォーマットと一致しているか。例えば、すべてのプロバイダの医療専門分野は有効な専門分野ですか？
関係性：記録されたデータは、指定された関係性制約と一致しているか。例えば、DRUG_EXPOSUREデータのPROVIDER_IDはPROVIDERテーブルに対応するレコードを持っているか？
計算。データに対する計算は意図した結果をもたらしますか? 例えば、身長と体重から計算されたBMIは、データに記録された一字一句のBMIと一致していますか？
完全性。特定の変数が存在するかどうか（例えば、医師の診察室で測定された体重が記録されているか）だけでなく、変数に記録されたすべての値が含まれているかどうか（例えば、すべての人が既知の性別を持っているか）を指します。
妥当性。データ値は信憑性があるか？3つのサブタイプが定義されています。
一意性。例えば、各PERSON_IDはPERSONテーブルで一度しか発生しませんか？
Atemporal: 値、分布、または密度は期待値と一致していますか? 例えば、データによって示唆された糖尿病の有病率は、既知の有病率と一致していますか?
時間的：値の変化は期待値と一致しているか？例えば、予防接種の順序は推奨事項に沿っているか？

1. **적합성(Conformance)**: 데이터값이 지정된 표준과 형식을 준수하는가? 3가지 하위 유형으로 식별된다:
   - **Value**: 기록된 데이터의 요소가 지정된 형식과 일치하는가? 예를 들어 모든 의료 제공자(Provider)의 진료과(specialties)는 유효한 전문 분야인가? 
   - **Relational**: 기록된 데이터가 지정된 관계적 제약(relational constraints)과 일치하는가? 예를 들어 DRUG_EXPOSURE 테이블의 PROVIDER_ID가 PROVIDER 테이블에도 상응하는 기록을 가지고 있는가? 
   - **Computation**: 데이터에 대한 계산이 의도한 결과를 산출하는가? 예를 들어 키와 몸무게에서 계산된 BMI와 데이터에 기록된 BMI가 일치하는가? 
2. **완전성(Completeness)**: 특정 변수가 존재하는지 여부 (예를 들어 진료실에서 측정된 체중이 기록되어 있는가?) 와 모든 변수의 값이 기록되어 있는지 (예를 들어 모든 사람이 성별에 관련된 데이터를 가지고 있는가?) 를 나타낸다.
3. **타당성(Plausibility)**: 데이터의 값을 믿을 수 있는가? 3가지 하위 유형으로 정의된다:
    - **Uniqueness**: 예를 들어 각각의 PERSON_ID는 PERSON 테이블에서 한 번만 발생하는가? 
    - **Atemporal**: 값, 분포 또는 밀도가 예상되는 값과 일치하는가? 예를 들어 데이터에 의해 암시된 당뇨병의 유행이 실제 알려진 유행과 일치하는가? 
    - **Temporal**: 값의 변화가 예상 범위 내에서 일어나는가? 예를 들어 예방접종 순서는 권고사항과 일치하는가? 
    
    \index{data quality!conformance} \index{data quality!completeness} \index{data quality!plausibility}

各コンポーネントは、2つの方法で評価することができます:

検証は、モデルやメタデータのデータ制約、システムの前提条件、ローカルな知識に焦点を当てます。外部参照には依存しません。検証の主な特徴は、ローカル環境内のリソースを使用して期待値と分布を決定できることです。
検証は、関連する外部ベンチマークに対するデータ値の整合性に焦点を当てます。外部ベンチマークのソースとしては、複数のデータサイト間の結果を組み合わせることが考えられます。

* **검증(Verification)** 외부 참조에 의존하지 않고 모델과 메타데이터의 데이터 제약, 시스템 추정, 그리고 Local 지식을 집중적으로 확인한다. Verification의 주요 특징은 Local 환경 내의 자원을 사용하여 예상되는 값과 분포를 설명하는 능력이다. 
* **검토(Validation)** 관련된 외부 기준(benchmarks)와 관련된 데이터 값과의 일치에 주력한다. 외부 기준(benchmark)로 가능한 원천으로는 다기관의 데이터를 결합한 결과가 될 수 있다. 

\index{data quality!verification} \index{data quality!validation}

### データ品質チェック

\index{ACHILLES} \index{data quality!checks}

Kahnは、データが所定の要件に適合しているかどうかをテストするデータ品質チェック（データ品質ルールと呼ばれることもある）という用語を紹介しています（例えば、不正確な出生年や死亡イベントの欠落の可能性があるために、患者の年齢141歳というありえない年齢にフラグを立てる）。自動化された DQ ツールを作成することで、このようなチェックをソフトウェアに実装することができる。そのようなツールの1つがACHILLES（Automated Characterization of Health Information at Large-scale Longitudinal Evidence Systems）である。Huser et al. 2018）ACHILLESは、CDMに準拠したデータベースの特性化と可視化を提供するソフトウェアツールである。そのため、データベースのネットワークにおけるDQを評価するために使用することができる。(Huser et al. 2016) ACHILLESはスタンドアロンのツールとして利用できるほか、「データソース」機能としてATLASに統合されている。

> Kahn은 데이터가 주어진 요구 조건을 준수하는지 확인하기 위해 데이터 품질 확인 (data quality check, 때로는 data quality rule이라고도 함)이라는 용어를 도입하였다 (예를 들어 부정확한 출생 연도 또는 사망 사건의 누락으로 인해 141세라는 환자의 신뢰할 수 없는 연령 자료 삭제). 우리는 자동화된 DQ tool을 만들어 소프트웨어 내에서 위와 같은 검사를 진행할 수 있다. 이러한 툴 중 하나가 [ACHILLES](https://github.com/OHDSI/Achilles) (Automated Characterization of Health Information at Large-scale Longitudinal Evidence Systems, ACHILLES)이다. [@huser_methods_2018] ACHILLES는 CDM에 부합하는 데이터베이스의 특성과 시각화를 제공하는 소프트웨어 툴이다. 따라서 데이터베이스 네트워크에서 DQ를 평가하는데 사용할 수 있다 [@huser_multisite_2016]. ACHILLES는 독립형 툴로써 사용 가능하며, "데이터 소스(Data Sources)" 기능으로 ATLAS에서도 통합되어 있다. \index{data quality!data quality check} \index{ACHILLES}

ACHILLESは170以上のデータ特性化分析を事前に計算しており、各分析には分析IDと分析の簡単な説明が付いています；そのような2つの例は、"715: DRUG_CONCEPT_IDによるDAYS_SUPPLYの分布 "と "506. 506: 性別別死亡時年齢の分布" これらの分析結果はデータベースに保存されており、WebビューアやATLASからアクセスすることができます。

> ACHILLES는 분석마다 분석 ID와 간단한 설명을 지닌 170개 이상의 데이터 특성 분석을 사전 계산한다. 이와 관련된 두 가지 예시는 다음과 같다. "715: DRUG_CONCEPT_ID에 의한 DAYS_SUPPLY의 분포" 그리고 "506: 성별에 따른 사망 연령 분포". 이러한 분석 결과는 데이터베이스에 저장되며, 웹 뷰어(web viewer) 또는 ATLAS에서 확인 할 수 있다. 

\index{Data Quality Dashboard}

DQ を評価するためにコミュニティが作成したもう 1 つのツールが Data Quality Dashboard（DQD）です。ACHILLES が特性分析を実行して CDM インスタンスの全体像を視覚的に把握するのに対し、DQD はテーブルごと、フィールドごとに、指定された仕様に適合していない CDM のレコード数を定量化します。全部で1,500以上のチェックが行われ、それぞれがカーンフレームワークに整理されています。各チェックの結果はしきい値と比較され、その値以上に違反している行のパーセンテージをFAILとみなします。表15.1にチェックの例を示します。

> 공동체에서 DQ 평가를 위해 만든 또 다른 툴로 [Data Quality Dashboard(DQD)](https://github.com/OHDSI/DataQualityDashboard)가 있다. ACHILLES가 특성화 분석을 실행하여 CDM 인스턴스(instance)에 대한 전반적인 시각적 이해를 제공한다면, DQD는 테이블별, 필드 별로 주어진 규격에 적합하지 않은 CDM의 레코드 수를 제공한다. 전체적으로, 1,500건 이상의 확인이 수행되고, 각 확인은 Kahn의 프레임워크로 구성된다. 각 DQ의 결과는 임계값과 비교되며, FAIL은 임계값을 위반하는 행을 백분율로 계산한 결과로 결정된다. 표 \@ref(tab:dqdExamples)은 확인의 예시를 보여준다. 

표: (\#tab:dqdExamples) Data Quality Dashboard에서 데이터 품질 규칙(Data Quality rules)의 예시.

| 위반 행의 분율 | 확인 내용 설명 | 임계값 | 상태 |
|:-------- |:------------------------------------ |:------ |:---- |
| 0.34| VISIT_OCCURRENCE의 provider_id가 CDM specification에 규정된 데이터 형식으로 확인되는가를 예 / 아니오로 나타낸 값. | 0.05 | FAIL|
| 0.99| MEASUREMENT 테이블의 measurement_source_value 필드에서 0으로 매핑된 소스 데이터의 수와 백분율. | 0.30 | FAIL|
| 0.09| DRUG_ERA 테이블의 drug_concept_id 필드에서 성분 등급에 적합하지 않은 값을 가진 레코드 수와 백분율. | 0.10 | PASS|
| 0.02| DRUG_EXPOSURE 테이블에서 verbatim_end_date 필드에 drug_exposure_start_date 이전에 발생한 값이 있는 레코드 수와 백분율.|0.05|PASS|
| 0.00| PROCEDURE_OCCURRENCE 테이블의 procedure_occurrence_id 필드에 중복되는 값이 있는 레코드 수와 백분율. | 0.00 | PASS|

ツール内では、チェックは複数の方法で構成されており、テーブル、フィールド、コンセプトレベルのチェックに分かれています。テーブルチェックは、CDM内の高レベルで行われるチェックで、例えば、すべての必要なテーブルが存在するかどうかを判断します。フィールドレベルのチェックは、CDMの仕様に準拠しているかどうか、すべてのテーブル内のすべてのフィールドを評価するように行われます。これには、すべての主キーが本当に一意であること、すべての標準概念フィールドが適切なドメインの概念IDを含んでいること、その他多くの確認が含まれます。概念レベルのチェックでは、もう少し深く、個々の概念IDを検査します。これらの多くは、性別固有の概念が誤った性別の人に起因していないことを確認するなど、Kahnフレームワークのもっともらしいカテゴリに該当します（例：女性患者の前立腺がん）。

> DQ 확인 툴은 여러가지 방법으로 구성되며 테이블, 필드, concept 수준의 확인이 예시가 될 수 있다. 테이블(table) 점검은 CDM내에서 상위 수준에서 수행되는 점검으로 예를 들면 모든 필수 테이블이 존재하는지를 확인하는 것이다. 필드 수준의 확인는 모든 테이블의 모든 필드가 CDM 규격에 적합한지 평가하는 방법으로 수행된다. 이는 모든 기본 키가 실제로 고유한지 확인하는 것과 모든 표준 concept 필드가 많은 concept_ID들 중 적절한 도메인의 concept_ID를 사용하는지 확인하는 것이 포함된다. Concept 수준의 검사는 개별적인 concept_id를 확인하기 위해 조금 더 깊이 들어간다.이 중 상당수가 Kahn의 프레임워크 중 개연성(Plausibility) 항목에 해당되며 성별과 관련된 특정 개념이 부적절한 성별에 할당되지 않도록 보장하는것이 예시로 해당된다 (예를 들어 여성 환자에서 전립선 암)

```{block2, type='rmdimportant'}
ACHILLES と DQD は、CDM のデータに対して実行されます。このように識別されたDQ問題は，CDMへの変換によるものかもしれませんが，ソースデータにすでに存在するDQ問題を反映しているかもしれません。変換に問題がある場合は、通常は問題を修正することができますが、基礎となるデータに問題がある場合は、問題のあるレコードを削除するしかないかもしれません。
ACHILLES와 DQD는 CDM 데이터를 대상으로 실행된다. 이렇게 식별된 DQ 문제는 CDM으로의 변환 과정이 원인일 수 있지만, 원본 데이터(source data)상에서 이미 존재하는 DQ 문제를 반영할 수도 있다. 만일 변환 과정의 문제로 확인되는 경우 일반적으로 문제 해결을 연구자의 역량 내에서 진행할 수 있지만, 원본 데이터의 오류로 인한 문제의 유일한 조치는 오류 데이터 자체를 삭제하는것이다.

```

### ETL ユニットテスト {#etlUnitTests}

\index{ETL!unit tests}

高レベルのデータ品質チェックに加えて、個々のレベルのデータチェックを行う必要があります。データがCDMに変換されるETL（Extract-Transform-Load）プロセスは非常に複雑であることが多く、その複雑さに伴い、気づかないうちにミスをしてしまう危険性があります。さらに、時間の経過とともにソースデータモデルが変更されたり、CDMが更新されたりすることがあり、ETLプロセスを変更する必要があります。ETLとして複雑なプロセスへの変更は、ETLのすべての側面を再考し、見直しする必要があり、意図しない結果をもたらす可能性があります。

> 상위 레벨의 데이터 품질 확인 뿐만 아니라, 개별 수준의 데이터 품질 확인도 수행되어야 한다. 데이터가 CDM으로 변환되는 ETL(추출-변환-적재, Extract-Transform-Load) 과정은 종종 상당히 복잡하고, 이러한 복잡성은 인해 실수를 눈치채지 못할 위험이 된다. 더욱이, 시간 경과에 지남에 따라 원본 데이터 모델이 변경되거나, CDM 버전이 업데이트 될 수 있으므로, ETL 과정를 수정이 필수적으로 진행되어야 한다. ETL과 같이 복잡한 과정의 변경은 의도하지 않은 결과를 초래할 수 있어, ETL의 모든 측면을 재고하고 검토해야 한다. 

ETLがやるべきことを確実に実行し、それを継続するためには、ユニットテストのセットを構築することを強くお勧めします。ユニットテストは、一つの側面を自動的にチェックする小さなコードです。第6章で説明したRabbit-in-a-Hatツールを使うと、このようなユニットテストを簡単に書くことができるユニットテストフレームワークを作成することができます。このフレームワークは、ソースデータベースとターゲットCDMバージョンのETLのために特別に作成されたR関数の集まりです。これらの関数のいくつかは、ソースデータスキーマに準拠した偽のデータエントリを作成するためのものですが、他の関数は、CDM形式のデータに期待されることを指定するために使用することができます。以下にユニットテストの例を示します。

> ETL의 향후 계획을 명확히 하고 지속적인 작업 진행을 위해 하나의 단위 검정(Unit test)을 구성하는것을 매우 권장한다. 단위 검정이란 하나의 측면을 자동으로 확인하는 작은 코드 조각이다. \@ref(ExtractTransformLoad)장에서 설명한 Rabbit-in-a-Hat 툴로 이러한 단위검정을 보다 쉽게 작성할 수 있는 단위 검정 프레임워크를 만들 수 있다.이 프레임 워크는 원본 DB와 대상으로 하는 CDM version의 ETL을 위해 특별히 작성된 R 함수의 집합이다. 이러한 함수 중 일부는 원천 데이터(source data) 스키마를 준수하는 가짜 데이터 항목을 만들기 위한 것이며, 다른 일부는 CDM 형식으로 데이터에 대한 예상값을 정하는 데 사용될 수 있다. 단위 검정에 대한 예시는 다음과 같다:


```{r eval=FALSE}
source("Framework.R")
declareTest(101, "Person gender mappings")
add_enrollment(member_id = "M000000102", gender_of_member = "male")
add_enrollment(member_id = "M000000103", gender_of_member = "female")
expect_person(PERSON_ID = 102, GENDER_CONCEPT_ID = 8507
expect_person(PERSON_ID = 103, GENDER_CONCEPT_ID = 8532)
```

この例では、Rabbit-in-a-Hat で生成されたフレームワークをソースとして、残りのコードで使用される関数をロードします。次に、人の性別のマッピングのテストを開始することを宣言します。ソーススキーマには ENROLLMENT テーブルがあり、Rabbit-in-a-Hat で作成した add_enrollment 関数を使用して、MEMBER_ID と GENDER_OF_MEMBER フィールドに異なる値を持つ 2 つのエントリを作成します。最後に、ETL後にPERSONテーブルに様々な値を持つ2つのエントリが存在することを想定しています。

> 예제에서, Rabbit-in-a-Hat에 의해 생성된 프레임워크는 나머지 코드에서 사용되는 함수를 불러오는 출처가 된다. 이후에 성별 매핑(Person gender mappings)에 대한 테스트를 시작할 것이라 선언하였다. 소스 스키마는 ENROLLMENT 테이블을 가지고 있고, 우리는 Rabbit-in-a-Hat에서 생성된 add_enrollment 함수를 사용하여 MEMBER_ID와 GENDER_OF_MEMBER 필드에 대해 서로 다른 값을 지닌 두 개의 항목을 만들었다. 마지막으로, ETL 이후 PERSON 테이블에서 다양한 예상값을 지닌 두 개의 항목이 존재해야 한다는 것을 명시한다. 

ENROLLMENTテーブルには他にも多くのフィールドがありますが、このテストのコンテキストでは、これらの他のフィールドがどのような値を持っているかはあまり気にしないことに注意してください。しかし、これらの値(例えば、生年月日)を空のままにしておくと、ETLがレコードを破棄したり、エラーを投げたりする可能性があります。テストコードを読みやすくしながらこの問題を克服するために、add_enrollment関数は、ユーザーが明示的に指定していないフィールドの値にデフォルト値（White Rabbitスキャンレポートで観測された最も一般的な値）を代入します。

> ENROLLMENT 테이블에는 다른 필드가 많이 존재하지만, 이 테스트의 맥락에서는 다른 필드가 어떤 값을 가지는지에 관해 설명하지 않을것이다. 하지만 이러한 값을 비워두면 (예를 들어 생년월일), 레코드를 삭제하거나 오류를 발생시키는 ETL의 원인이 될 수 있다. 테스트 코드를 읽기 쉽게 유지하면서 이러한 문제를 해결하기 위해서, add_enrollment 함수는 사용자가 명확하게 지정하지 않은 필드의 값에 기본값 (White Rabbit 스캔 보고서에서 관찰된 가장 일반적인 값) 을 할당한다. 

同様のユニットテストは、ETL内の他のすべてのロジックに対して作成することができ、通常は何百ものテストになります。テストの定義が終わったら、フレームワークを使って2つのSQL文のセットを生成し、1つは偽のソースデータを作成し、もう1つはETLで作成したデータのテストを作成します。

> ETL의 모든 다른 논리에 대해 유사한 Unit test가 만들어질 수 있으며, 일반적으로 수백 개의 시험을 진행할 수 있다. 테스트를 정의하는것이 끝나면 프레임워크를 사용하여 두 개의 SQL 구문 세트를 만들 수 있다. 하나는 가짜 원본 데이터를 만드는 것이고, 다른 하나는 ETL된 데이터에 대한 테스트를 진행할 수 있는 구문이다. 

```{r eval=FALSE}
insertSql <- generateInsertSql(databaseSchema = "source_schema")
testSql <- generateTestSql(databaseSchema = "cdm_test_schema")
```

전반적인 과정은 그림 \@ref(fig:testFramework)에 묘사된 것과 같다.

```{r testFramework, fig.cap='Rabbit-in-a-Hat 테스팅 프레임워크를 사용한 추출변환적재(ETL) Unit testing 과정.',echo=FALSE, out.width='90%', fig.align='center'}
knitr::include_graphics("images/DataQuality/testFramework.png")
```

SQL을 통한 테스트는 표 \@ref(tab:exampleTestResults)와 같은 테이블을 반환한다. 이 표에서는 우리가 앞서 정의한 두 가지 테스트를 통과하는 것을 알 수 있다.

Table: (\#tab:exampleTestResults) ETL 단위 검정 결과 예시.

| ID    | 설 명          | 상 태 |
|:-----:|:---------------------- |:------:|
| 101   | 성별 매핑(Person gender mappings) | PASS   |
| 101   | 성별 매핑(Person gender mappings) | PASS   |

これらのユニットテストの威力は、ETLプロセスが変更されても、いつでも簡単に再実行できることです. 

## 研究に特化したチェック

\index{data quality!study-specific checks}

この章では、これまで一般的なDQチェックに焦点を当ててきた。このようなチェックは、研究にデータを使用する前に実行されるべきである。これらのチェックは研究の質問に関係なく行われるので、研究に特化したDQ評価を行うことをお勧めします。

> 본 장에서는 지금까지 보편적인 DQ 검사에 초점을 맞췄다. 이러한 검사들은 데이터가 연구에 사용되기 이전에 실행되어야 한다. 이러한 검사는 연구 문제와 무관하게 수행되어야 하므로 연구 목적의 DQ 평가를 수행할 것을 권한다. 

これらの評価のいくつかは、研究に特に関連する DQ ルールの形をとることができる。例えば、関心のある曝露の記録の少なくとも90％が曝露の長さを特定しているという規則を課したいと思うかもしれません。

> 이러한 평가 중 일부는 특별히 연구와 관련된 DQ rule의 형태를 취할 수 있다. 예를 들어, 관심 노출에 대한 레코드의 최소 90%가 노출 기간을 명시한다는 새로운 rule의 도입을 원할 수도 있다. 

標準的な評価は、ACHILLESでの研究に最も関連する概念、例えば研究コホートの定義で指定されている概念をレビューすることである。コードが観察される率の経時的な突然の変化は、DQの問題を示唆しているかもしれません。いくつかの例については、この章で後述する。

> 표준으로 시행하는 검사는 연구와 가장 관련된 concept들, 예로들어 코호트 정의에서 정의된 concept들을 ACHILLES에서 검토하는 것이다. 전체기간에서 특정 코드의 사용 빈도가 급격히 변한다면 이것은 DQ 문제가 있다는 것을 알려주는 힌트가 될 수도 있다. 몇몇 예시들은 이 장의 뒷부분에서 recommend를 설명하고 있다. 

もう一つの評価は、この研究のために開発されたコホート定義を用いて作成されたコホートの有病率と経時的な有病率の変化を検討し、それらが外部の臨床知識に基づく予想と一致しているかどうかを確認することである。例えば、新薬の曝露は、市場に導入される前には存在しないはずであり、導入後は時間の経過とともに増加する可能性が高い。同様に、アウトカムの有病率は、母集団における状態の有病率について知られていることと一致していなければならない。研究がデータベースのネットワーク全体で実施される場合、データベース間でコホートの有病率を比較することができる。あるコホートがあるデータベースでは有病率が高いが、別のデータベースでは欠落している場合、DQの問題があるかもしれません。このような評価は、第16章で議論した臨床的妥当性の概念と重なることに注意してください。DQの問題ではなく、我々のコホートの定義が我々が関心を持っている健康状態を真に捉えていないため、あるいは、これらの健康状態が異なる患者集団を捉えているデータベース間で正しく異なるために、いくつかのデータベースで予想外の有病率が見られるかもしれません。

> 또 다른 평가는 연구를 위해 설정된 코호트 정의를 사용해 생성된 코호트 결과에 대한 유병률과 시간에 따른 유병률의 변화를 검토하고 이것이 외부 임상 지식에 기반한 예상값과 일치하는지 확인하는 것이다. 예를 들어, 신약의 노출은 시장에 소개되기 전에는 없어야 하고, 도입 이후에 시간이 지남에 따라 증가할 가능성이 있다. 유사하게 결과에 대한 유병률은 모집단에서 질환의 유병률에 대해 알려진 것과 일치해야 한다. 만약 연구가 데이터베이스의 네트워크에서 실행한다면, 우리는 데이터베이스 간의 코호트 유병률을 비교할 수 있다. 한 데이터베이스에서 높은 유병률을 보이지만, 다른 데이터베이스에서는 누락된 경우, DQ 문제가 있을 수 있다. 이러한 평가는 \@ref(ClinicalValidity)장에서 논의한 바와 같이, *clinical validity*의 개념과 중복된다는 것을 유의해야 한다. 몇몇의 데이터베이스에서는 예상하지 못한 유병률 결과가 나올수가 있는데, 이는 DQ 문제가 아니라 코호트 정의에서 연구 주제와 부합하는 건강 상태를 온전히 잡아내지 못했거나 데이터베이스마다 환자 모집단이 상이하여 발생할 수 있다.


### マッピングの確認

私たちがしっかりと管理しているエラーの原因の 1 つは、ソース コードと標準概念とのマッピングです。語彙のマッピングは細心の注意を払って作成されており、コミュニティのメンバーが指摘したマッピングのエラーは、語彙の問題追跡57 に報告され、将来のリリースで修正されます。とはいえ、すべてのマッピングを手作業で完全にチェックすることは不可能であり、エラーはまだ存在する可能性があります。したがって、研究を行う際には、研究に最も関連性の高い概念のマッピングを確認することをお勧めします。幸いなことに、CDM には標準概念だけでなく、ソース・コードも保存されているので、これは非常に簡単に達成できます。研究で使用されている概念にマッピングされているソースコードとそうでないソースコードの両方をレビューすることができます。

> 우리가 통제할 수 있는 오류의 원인 중 한 가지는 원천 코드를 표준 concept에 매핑하는 것이다. 용어 매핑은 정교하게 제작되었으며, 매핑상의 문제가 있다면 공동체 구성원에 의해 발견되어 [^vocabIssueTrackerUrl]에 보고 된후 다음 업데이트에 반영된다. 그런데도 불구하고 모든 매핑을 직접 확인하는 것은 불가능하고 오류가 계속 존재할 수 있다. 그렇기때문에, 연구를 수행할 때 연구와 관련있는 concept들의 매핑을 검토해보는 것을 권장한다. 다행히도, CDM에서 표준 용어(Concept) 뿐만 아니라 소스 코드도 같이 저장하기 때문에 이러한 작업은 쉽게 할 수 있다. 연구에 사용된 concept에 매핑된 소스 코드뿐만 아니라 그렇지 않은 소스 코드도 검토할 수 있다.

[^vocabIssueTrackerUrl]: https://github.com/OHDSI/Vocabulary-v5.0/issues

マップされたソース・コードを確認する1つの方法は、MethodEvaluation RパッケージのcheckCohortSourceCodes関数を使用することです。この関数は、ATLASによって作成されたコホート定義を入力として使用し、コホート定義で使用された各概念セットについて、どのソース・コードがセット内の概念にマッピングされているかをチェックします。また、特定のソースコードに関連する時間的な問題を特定するのに役立つように、これらのコードの有病率を経時的に計算します。図15.2の出力例は、"Depressive disorder "と呼ばれる概念セットの（部分的な）内訳を示しています。この概念セットの中で最も普及している概念は、データベース内の概念 440383 ("Depressive disorder")である。データベース内の3つのソースコードがこの概念に対応していることがわかる。ICD-9コード3.11、およびICD-10コードF32.8とF32.89である。左側では、全体としての概念が最初に時間の経過とともに徐々に増加していることがわかりますが、その後急激な低下を示しています。個々のコードを見てみると、この落ち込みは、ICD-9 コードが使われなくなった時期に説明がつくことがわかります。これは、ICD-10 コードが使用され始めるのと同じ時期であるにもかかわらず、ICD-10 コードの合計有病率は、ICD-9 コードよりもはるかに小さい。この具体的な例は、ICD-10 コード F32.9（「大うつ病性障害、単一エピソード、特定不能」）も概念にマッピングされるべきであったという事実に起因している。この問題はその後、語彙集で解決されている。

> 소스 코드를 검토하는 한 가지 방법은 [MethodEvaluation](https://ohdsi.github.io/MethodEvaluation/) R 패키지의 `checkCohortSourceCodes` 함수를 사용하는 것이다. 이 함수는 ATLAS에서 생성된 코호트 정의를 input으로 사용하고 코호트 정의에서 사용된 각 concept 세트에 대해 concept과 매핑되는 소스 코드를 확인한다. 또한 전체 기간에 대한 코드들의 빈도를 계산하여 특정 코드에서 발생하는 시간적인 문제들을 확인하는데 도움이 될 수 있다. 그림 \@ref(fig:sourceCodes) 예시 결과는 "우울증 (Depression disorder)"이라 불리는 concpet 세트의 분석을 보여준다. 관심 분야의 데이터베이스에서 이 concept 세트의 가장 보편적인 concept은 [440383](http://athena.ohdsi.org/search-terms/terms/440383) (우울증; Depressive disorder)이다. 데이터베이스 내의 ICD-9 코드의 3.11, ICD-10 코드의 F32.8과 F32.89 이 세가지 코드가 해당 concept으로 매핑이 된 걸 볼 수 있다. 그림의 왼쪽부터 보면 전체로서의 concept은 시간이 지남에 따라 초반에는 증가하지만 그 후에 급격이 감소하는 것을 볼 수 있다. 개별 코드를 살펴보면, 이러한 하락은 하락 시점에 ICD-9 코드의 사용이 중단되는 것으로 설명될 수 있다는 것을 알 수 있다. 이것이 ICD-10 코드가 사용되기 시작한 것과 같은 시간임에도 불구하고, 결합된 ICD-10 코드의 빈도가 ICD-9 코드의 빈도보다 훨씬 적다. 이 구체적인 예시는 ICD-10 코드 F32.9 ("주요 우울 장애, 단일 에피소드, 불특정") 도 이 concept으로 매핑돼야 했었기 때문이다. 이 문제는 Vocabulary에서 해결되었다.

```{r sourceCodes, fig.cap='checkCohortSourceCodes 기능의 output 예시. ',echo=FALSE, out.width='100%', fig.align='center'}
knitr::include_graphics("images/DataQuality/sourceCodes.png")
```

前の例では、マッピングされていないソースコードを偶然見つけたことを示しましたが、一般的には、マッピングが存在するかどうかを確認するよりも、マッピングが存在しないかどうかを特定する方が難しいです。どのソースコードがマッピングされるべきなのにマッピングされないのかを知る必要があります。この評価を半自動で行う方法は、MethodEvaluation R パッケージの findOrphanSourceCodes 関数を使用することです。この関数は、単純なテキスト検索を使ってソースコードの語彙を検索し、ソースコードが特定の概念にマッピングされているか、その概念の子孫にマッピングされているかをチェックします。結果として得られるソースコードのセットは、その後、手元のCDMデータベースに表示されるものだけに制限されます。例えば、ある研究では、"Gangrenous disorder"（439928）という概念とその子孫のすべてが、壊疽のすべての発生を検索するために使用されました。これが本当に壊疽を示すすべてのソースコードを含んでいるかどうかを評価するために、いくつかの用語（例えば、"壊疽"）を使用して、CONCEPTおよびSOURCE_TO_CONCEPT_MAPテーブルの記述を検索し、ソースコードを特定した。その後、自動検索は、データに現れる各壊疽のソースコードが、実際に直接または間接的に（祖先を介して）"Gangrenous disorder "という概念にマップされているかどうかを評価するために使用される。この評価の結果を図 15.3 に示すが、ICD-10 コード J85.0（「肺の壊疽と壊死」）は、"壊疽性障害 "の子孫ではない概念 4324261（「肺壊死」）にしかマッピングされていないことが明らかになった。

> 앞의 예시는 매핑되지 않은 소스 코드를 발견하는 것을 묘사한 것으로, 일반적으로 누락된 매핑을 식별하는 것이 존재하는 매핑을 확인하는것 보다 더 어렵다. 이는 어떤 소스 코드가 매핑되어야 하지만 매핑되지 않았는지 알아야 한다. 이를 평가하는 반-자동화된 방법은 [MethodEvaluation](https://ohdsi.github.io/MethodEvaluation/) R 패키지의 `findOrphanSourceCodes` 함수를 사용하는 것이다. 이 함수는 간단한 텍스트 검색을 통해 소스 코드에 대한 Vocabulary를 검색할 수 있게 하고, 이 소스 코드가 특정 concept이나 그 concept의 하위 concept 중 하나와 매핑되는지 여부를 확인한다. 소스 코드의 결과는 현재 CDM 데이터베이스에 나타나는 코드로만 제한된다. 예를 들어, "괴저 장애(Gangrenous disorder)" ([439928](http://athena.ohdsi.org/search-terms/terms/439928)) 와 모든 하위 concept들은 모든 괴저 발생을 찾기 위해 사용되었다. 이것이 실제로 괴저를 나타내는 모든 소스 코드를 포함하는지 여부를 평가하기 위해, 소스 코드를 식별하기 위한 CONCEPT 테이블과 SOURCE_TO_CONCEPT_MAP 테이블의 설명을 검색하는데 몇 가지 용어(예를 들어 "괴저(gangrene)")가 사용되었다. 자동 검색은 데이터에 나타나는 각 괴저 코드가 "괴저 장애 (Gangrenous disorder)"라는 concept에 직접 또는 간접적으로 매핑되었는지 여부를 평가하기 위해 사용된다. 이러한 평가의 결과는 그림 \@ref(fig:missingMapping)와 같으며, ICD-10 코드 J85.0 ("폐의 괴저 및 괴사"; Gangrene and necrosis of lung)은 "괴저 장애(Gangrenous disorder)의 하위 concept이 아닌 concept [4324261](http://athena.ohdsi.org/search-terms/terms/4324261) ("폐 괴사"; Pulmonary necrosis)에만 매핑되었다. \index{orphan codes}

```{r missingMapping, fig.cap='orphan 소스 코드 예시. ',echo=FALSE, out.width='70%', fig.align='center'}
knitr::include_graphics("images/DataQuality/missingMapping.png")
```

## ACHILLES 演習 {#achillesInPractice}

ここでは、CDM形式のデータベースに対してACHILLESを実行する方法を示します。

> 여기서는 CDM 형식의 데이터베이스에 대해 ACHILLES를 실행하는 방법을 보여준다.

まず、サーバーへの接続方法をRに伝える必要があります。ACHILLES は DatabaseConnector パッケージを使用しており、createConnectionDetails という関数を提供しています。createConnectionDetails と入力すると、さまざまなデータベース管理システム (DBMS) に必要な特定の設定を行うことができます。例えば、以下のコードを使用して PostgreSQL データベースに接続することができます。

> 먼저, R에서 서버를 연결하는 방법에 대해 설명할 필요가 있다. ACHILLES는 `createConnectionDetails`라는 함수를 제공하는 [DatabaseConnector](https://ohdsi.github.io/DatabaseConnector/) 패키지를 사용한다. 다양한 데이터베이스 관리 시스템(Database management systems, DBMS)에 필요한 특정 설정을 `?createConnectionDetails`을 입력하여 확인할 수 있다. 예를 들어, 다음 코드를 이용하여 PostgreSQL과 연결할 수 있다:


```{r tidy=FALSE, eval=FALSE}
library(Achilles)
connDetails <- createConnectionDetails(dbms = "postgresql",
                                       server = "localhost/ohdsi",
                                       user = "joe",
                                       password = "supersecret")

cdmDbSchema <- "my_cdm_data"
cdmVersion <- "5.3.0"
```

最後の 2 行は、CDM のバージョンと同様に cdmDbSchema 変数を定義します。これらを後で使用して、CDM フォーマットのデータがどこにあるのか、そしてどのバージョンの CDM が使用されているのかを R に伝えることになります。Microsoft SQL Server の場合、データベーススキーマはデータベースとスキーマの両方を指定する必要があることに注意してください。

> 마지막 두 줄은 CDM 버전뿐만 아니라 `cdmDbSchema` 변수를 정의한다. 이를 사용하여 CDM 형식의 데이터가 어디에 있는지, 어떤 버전의 CDM이 사용되었는지 R에 입력한다. Microsoft SQL Server의 경우, `cdmDbSchema <- "my_cdm_data.dbo"`와 같이 데이터베이스와 스키마를 모두 지정해야 한다.

다음으로, ACHILLES를 실행한다:


```{r tidy=FALSE, eval=FALSE}
result <- achilles(connectionDetails,
                   cdmDatabaseSchema = cdmDbSchema,
                   resultsDatabaseSchema = cdmDbSchema,
                   sourceName = "My database",
                   cdmVersion = cdmVersion)
```

この関数は、ここではCDMデータと同じデータベーススキーマに設定したresultsDatabaseSchemaにいくつかのテーブルを作成します。

> 이 함수는 `resultsDatabaseSchema`에 여러 테이블을 생성하며, 여기에서는 CDM 데이터와 동일한 데이터베이스 스키마로 설정하였다. 

ACHILLESデータベースの特性を見ることができます。これは、ATLASをACHILLES結果データベースにポイントするか、ACHILLES結果をJSONファイルのセットにエクスポートすることで行うことができます。

> ATLAS를 ACHILLES 결과 데이터베이스로 지정하거나 ACHILLES 결과들를 JSON 파일들로 내보내서 ACHILLES 데이터베이스의 특징을 볼 수 있다:


```{r eval=FALSE}
exportToJson(connectionDetails,
             cdmDatabaseSchema = cdmDatabaseSchema,
             resultsDatabaseSchema = cdmDatabaseSchema,
             outputPath = "achillesOut")
```

JSON ファイルは achillesOut サブフォルダーに書き込まれ、AchillesWeb ウェブアプリケーションと一緒に使用して結果を調べることができます。例えば、図15.4はACHILLESのデータ密度プロットを示しています。このプロットを見ると、データの大部分が2005年から始まっていることがわかります。しかし、1961年頃からの記録もいくつかあるようですが、これはデータの誤りである可能性が高いです。

> JSON 파일은 achillesOut 하위 폴더에 작성되고, 결과 확인을 위해 AchillesWeb 웹 어플리케이션과 함께 사용할 수 있다. 예를 들어, 그림 \@ref(fig:achillesDataDensity) ACHILLES 데이터 밀도 plot을 보여준다. 이 plot은 2005년에 시작된 대량의 데이터를 보여준다. 하지만 1961년경에 몇 개의 레코드가 있는 것으로 나타나며, 이는 데이터에 오류가 있는 것일 수도 있다. 

```{r achillesDataDensity, fig.cap='ACHILLES 웹 뷰어의 데이터 밀도 그림.',echo=FALSE, out.width='100%', fig.align='center'}
knitr::include_graphics("images/DataQuality/achillesDataDensity.png")
```

もう一つの例を図 15.5 に示すが、糖尿病診断コードの有病率の急激な変化を示している。この変化は、この特定の国での診療報酬規則の変更と一致しており、診断数の増加につながっているが、おそらく基礎となる人口の有病率が真の意味で増加しているわけではないだろう。

> 또 다른 예시로는 그림 \@ref(fig:achillesCodeChange)로, 당뇨병 진단 코드의 유병률에 급격한 변화를 보여주고 있다. 이러한 변화는 특정 국가에서 보험 청구 규정이 변경됨에 따라 진단수가 증가한 것이지 실제로 유병률이 증가한 것은 아니다.

```{r achillesCodeChange, fig.cap='ACHILLES 웹 뷰어에서 코딩된 월별 당뇨병 발생률.',echo=FALSE, out.width='100%', fig.align='center'}
knitr::include_graphics("images/DataQuality/achillesCodeChange.png")
```
## Data Quality Dashboard 実習 (Data Quality Dashboard in Practice) {#dqdInPractice}

ここでは、CDM形式のデータベースに対してData Quality Dashboardを実行する方法を実演します。これには、セクション15.4で説明したCDM接続に対する大量のチェックを実行します。現在のところ、DQDはCDM v5.3.1のみをサポートしているので、接続する前にデータベースが正しいバージョンであることを確認してください。ACHILLESと同様に、データをどこで探すかをRに伝えるために変数cdmDbSchemaを作成する必要があります。

> 여기에서는 CDM 형식의 데이터베이스에서 Data Quality Dashboard를 실행하는 방법을 보여준다. \@ref(achillesInPractice)절에서 설명한 CDM conncection에 대해 더 많은 checks를 수행한다. 현재 DQD는 CDM v5.3.1만 지원하기 때문에 실행 전 데이터베이스가 올바른 버전인지 확인이 필요하다. ACHILLES와 마찬가지로 `cdmDbSchema`를 작성하여 데이터를 찾을 위치를 R에 입력해야 한다. 

```{r eval=FALSE}
cdmDbSchema <- "my_cdm_data.dbo"
```

다음으로, Dashboard를 실행한다...

```{r eval=FALSE}
DataQualityDashboard::executeDqChecks(connectionDetails = connectionDetails, 
                                      cdmDatabaseSchema = cdmDbSchema, 
                                      resultsDatabaseSchema = cdmDbSchema,
                                      cdmSourceName = "My database",
                                      outputFolder = "My output")
```

上記の関数は、指定されたスキーマに対して利用可能なすべてのデータ品質チェックを実行します。そして、ここでは CDM と同じスキーマに設定した resultsDatabaseSchema にテーブルを書き込みます。このテーブルには、CDMテーブル、CDMフィールド、チェック名、チェックの説明、Kahnカテゴリとサブカテゴリ、違反行の数、しきい値レベル、チェックの合格・不合格など、各チェックの実行に関するすべての情報が含まれます。この関数は、テーブルに加えて、outputFolderとして指定された場所にJSONファイルを書き込みます。このJSONファイルを使用して、Webビューアを起動して結果を検査することができます。

> 위의 함수는 지정된 스키마에서 사용 가능한 모든 데이터 품질 checks를 실행한다. 그런 다음 CDM과 동일한 스키마로 설정한 `resultsDatabaseSchema`에 테이블을 작성한다. 이 테이블은 CDM 테이블, CDM 필드, 검사명, 설명, Kahn의 카테고리와 하위 카테고리, 위반 행의 수, 임계값 레벨 그리고 검사의 통과여부 등 각 check의 실행에 대한 모든 정보가 포함된다. 이 함수는 테이블뿐만 아니라 `outputFolder`로 JSON 파일을 작성할 위치를 지정한다. JSON 파일을 사용해서 웹 뷰어를 시작해 결과를 확인할 수 있다. 

```{r eval=FALSE}
viewDqDashboard(jsonPath)
```

`jsonPath` 변수는 위의 `executeDqChecks` 함수가 호출될 때, 지정된 `outputFolder`에 위치한 Dashboard의 결과가 포함된 JSON 파일의 경로여야 한다. 

変数 jsonPath には、上記の executeDqChecks 関数を呼び出した際に指定した outputFolder にある Dashboard の結果を含む JSON ファイルへのパスを指定する必要があります。

ダッシュボードを最初に開 く と 、 図 15.6 に示す よ う に概要表が表示 さ れます。この表には、各 Kahn カテゴリで実行されたチェックの総数がコンテキスト別に表示され、それぞれのカテゴリでパスした数とパーセンテージ、および全体のパス率が表示されます。

> 처음 Dashoboaard를 열면 그림 \@ref(fig:dqdOverview)과 같이 개요 테이블이 표시된다. 여기에는 내용별 Kahn의 카테고리에서 실행된 총 검사의 수, 각 검사의 PASS 수와 백분율 및 전체 PASS 비율이 표시된다.

```{r dqdOverview, fig.cap='Data Quality Dashboard 에서의 데이터 품질 점검 개요.',echo=FALSE, out.width='100%', fig.align='center'}
knitr::include_graphics("images/DataQuality/dqdOverview.png")
```

左側のメニューで「Results」をクリックすると、実行された各チェックのドリルダウン結果が表示される（図 15.7）。この例では、個々の CDM テーブルの完全性を判断するために実行されたチェック、または指定されたテーブルに少なくとも 1 つのレコードがある CDM 内の人物の数とパーセンテージを示すテーブルが表示されています。この場合、一覧表示されている5つのテーブルはすべて空で、ダッシュボードでは「失敗」とカウントされます。アイコンをクリックすると、表示された結果を生成するためにデータに対して実行されたクエリが正確に表示されるウィンドウが開きます。これにより、Dashboard が失敗と判断した行を簡単に特定することができます。

> 왼쪽 메뉴에서 *Results*를 클릭하면 실행된 각 검사에 대한 상세 결과 페이지로 이동한다 (그림 \@ref(fig:dqdResults) 참조). 예시의 테이블은 개별적인 CDM 테이블의 완전성을 확인하거나 CDM에서 특정 테이블에 최소 1개 이상의 레코드를 가진 인원수 및 백분율을 확인하기 위한 검사에 대한 것이다. 이 경우 나열된 5개의 테이블이 Dashboarc에 Fail로 나타났으며 모두 비어있다. ![](images/DataQuality/plusIcon.png) 아이콘을 클릭하면 나열된 결과를 생성하기 위해 데이터에서 실행된 정확한 쿼리를 보여주는 창이 열린다. 이를 통해 Dashboard에서 Fail로 간주한 행을 쉽게 식별할 수 있다. 

```{r dqdResults, fig.cap='Drilldown into Data Quality Checks in the Data Quality Dashboard 에서의 데이터 품질 구체적 관찰.',echo=FALSE, out.width='100%', fig.align='center'}
knitr::include_graphics("images/DataQuality/dqdResults.png")
```

## 研究に特化したチェックの実習

次に、付録B.4で提供されている血管性浮腫コホート定義に特化したいくつかのチェックを実行する。15.4節で説明したように接続の詳細が設定されており、コホート定義のJSONとSQLがそれぞれ "cohort.json "と "cohort.sql "というファイルに保存されていると仮定します。JSONとSQLは、ATLASのコホート定義機能のExportタブから取得できます。

> 다음으로, 부록 \@ref(Angioedema)에 제공된 혈관 부종 코호트 정의에 대한 몇 가지 검사를 수행할 것이다. \@ref(achillesInPractice)절에 설명된 것처럼 연결 세부사항이 설정되어 있고, 코호트 정의 JSON과 코호트 정의에 대한 SQL이 각각 "cohort.json"과 "cohort.sql" 파일에 저장되어있다고 가정한다. JSON 파일과 SQP 파일은 ATLAS 코호트 정의 기능의 내보내기 탭에서 얻을 수 있다.


```{r eval=FALSE}
library(MethodEvaluation)
json <- readChar("cohort.json", file.info("cohort.json")$size)
sql <- readChar("cohort.sql", file.info("cohort.sql")$size)
checkCohortSourceCodes(connectionDetails,
                       cdmDatabaseSchema = cdmDbSchema,
                       cohortJson = json,
                       cohortSql = sql,
                       outputFile = "output.html")
```


図15.8に示すように、出力ファイルをWebブラウザで開くことができます。ここでは、血管性浮腫コホートの定義が2つの概念セットを持っていることがわかります。"入院患者またはER訪問」と「血管性浮腫」です。この例のデータベースでは、訪問はデータベース固有のソース・コード "ER "と "IP "から発見されたが、これはボキャブラリーには含まれていない。また、血管性浮腫は1つのICD-9と2つのICD-10コードから発見されていることがわかります。個々のコードのスパークラインを見ると、2 つのコーディングシステム間のカットオーバーの時点が明確に見えますが、概念セット全体としては、その時点では不連続性はありません。

> 그림 \@ref(fig:sourceCodesAngioedema)과 같이 웹 브라우저에서 output(출력) 파일을 열 수 있다. 여기서 혈관 부종 코호트 정의에 "Inpatient or ER visit"과 "Angioedema" 두 가지 concept이 있는 것을 확인할 수 있다. 이 예제 데이터베이스에서, 방문은 ETL 중에 표준 concept과 매핑되었지만, Vocabulary에는 없는, "ER"과 "IP"라는 데이터베이스 특정 소스 코드를 통해 발견되었다. 혈관 부종은 하나의 ICD-9 코드와 두 개의 ICD-10 코드를 통해 발견되었다. 개별 코드에 대한 스파크 라인(spark-line)을 봤을 때, 두 가지 코딩 시스템 간의 컷 오버(cut-over) 시점을 명확하게 알 수 있지만, 전체적인 concept에서는 불연속성이 없다. 

```{r sourceCodesAngioedema, fig.cap='Angioedema 코호트 정의에서 사용된 소스 코드.',echo=FALSE, out.width='100%', fig.align='center'}
knitr::include_graphics("images/DataQuality/sourceCodesAngioedema.png")
```

次に、標準概念コードにマッピングされていないソースコードであるオーファンソースコードを検索することができます。ここでは、標準概念 "血管性浮腫 "を探し、次に、"血管性浮腫 "またはその名前の一部として提供する同義語を持つコードおよび概念を探します。

> 다음으로, 표준 concept 코드에 매핑되지 않은 소스 코드인 orphan 소스 코드를 검색할 수 있다. 표준 concept인 "혈관 부종(Angioedema)"을 찾은 다음 "혈관 부종" 또는 그 이름이 일부 포함되어 있거나 동의어가 있는 concept과 코드를 찾는다:

```{r eval=FALSE}
orphans <- findOrphanSourceCodes(connectionDetails,
                                 cdmDatabaseSchema = cdmDbSchema,
                                 conceptName = "Angioedema",
                                 conceptSynonyms = c("Angioneurotic edema",
                                                     "Giant hives",
                                                     "Giant urticaria",
                                                     "Periodic edema"))
View(orphans)
```
|code              |설명                                                            |vocabularyId | overallCount|
|:-----------------|:----------------------------------------------------------------------|:------------|------------:|
|T78.3XXS          |Angioneurotic edema, sequela                                           |ICD10CM      |          508|
|10002425          |Angioedemas                                                            |MedDRA       |            0|
|148774            |Angioneurotic Edema of Larynx                                          |CIEL         |            0|
|402383003         |Idiopathic urticaria and/or angioedema                                 |SNOMED       |            0|
|232437009         |Angioneurotic edema of larynx                                          |SNOMED       |            0|
|10002472          |Angioneurotic edema, not elsewhere classified                          |MedDRA       |            0|

データの中で実際に使用されている唯一の潜在的なオーファンは「血管性浮腫、後遺症」であり、血管性浮腫にマッピングされるべきではない。したがって、この分析では、欠落したコードは発見されなかった。

> 데이터에서 실제로 사용된 유일한 잠재적 orphan 코드는 "혈관신경성 부종, 후유증(Angioneurotic edema, sequela)"이며, 이는 혈관 부종과 매핑되어서는 안 된다. 따라서 이 분석에서는 누락된 코드가 발견되지 않았다.

## まとめ

```{block2, type='rmdsummary'}
- 대부분의 관찰형 의료 데이터는 연구를 위해 수집되지 않는다. 

- 데이터 품질은 데이터가 연구 목적에 적합한지를 확인하기 위해 평가되어야 한다. 

- 보편적인 연구 목적을 위해, 특정 연구의 맥락에서 비판적으로 데이터 품질을 평가해야 한다.

- 데이터 품질의 일부 측면은 Data Quality Dashboard의 예시와 같이 사전 정의된 많은 규칙을 통해 자동적으로 평가될 수 있다. 

- 특정 연구와 관련된 코드 매핑을 평가하기 위한 다른 툴들이 있다.

```

## エクササイズ

#### 前提条件 {-}

これらの演習では、項8.4.5で説明されているように、R、R-Studio、Javaがインストールされていることを前提としています。また、SqlRender、DatabaseConnector、ACHILLES、およびEunomiaパッケージも必要です。

> 예제 실습을 위해 \@ref(installR)절에서 설명한 것과 같이 R, R-studio 및 Java가 설치되어 있다고 가정한다. 또한 [SqlRender](https://ohdsi.github.io/SqlRender/), [DatabaseConnector](https://ohdsi.github.io/DatabaseConnector/), [ACHILLES](https://github.com/OHDSI/Achilles) 및 [Eunomia](https://ohdsi.github.io/Eunomia/) 패키지가 필요하다. 아래의 코드를 사용하여 설치할 수 있다:


```{r eval=FALSE}
install.packages(c("SqlRender", "DatabaseConnector", "devtools"))
devtools::install_github("ohdsi/Achilles")
devtools:install_github("ohdsi/DataQualityDashboard")
devtools::install_github("ohdsi/Eunomia", ref = "v1.0.0")
```

Eunomiaパッケージは、ローカルのRセッション内で実行されるCDM内のシミュレートされたデータセットを提供します。接続の詳細は、以下を使用して取得することができます。

> Eunomia 패키지는 로컬 R 세션 내에서 실행되는 CDM에서 시뮬레이션 된 데이터 세트를 제공한다. 자세한 접속정보는 아래를 활용하여 얻을 수 있다:


```{r eval=FALSE}
connectionDetails <- Eunomia::getEunomiaConnectionDetails()
```

CDM 데이터베이스 스키마는 "main"이다.

```{exercise, exerciseRunAchilles}
Eunomia 데이터베이스에 대해 ACHILLES를 실행하십시오.

```

```{exercise, exerciseRunDQD}
Eunomia 데이터베이스에 대해 DataQaulityDashbiard를 실행하십시오.

```

```{exercise, exerciseViewDQD}
DQD 검사 목록을 추출하십시오.

```

제안된 답변은 부록 \@ref(DataQualityanswers)에서 찾을 수 있다.

